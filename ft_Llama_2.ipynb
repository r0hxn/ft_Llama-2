{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/r0hxn/ft_Llama-2/blob/main/ft_Llama_2.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MBd_xSjfvjGM",
        "outputId": "2410a7c6-1145-4539-a5f0-daaf93fb6464"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "  Building wheel for transformers (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m270.9/270.9 kB\u001b[0m \u001b[31m2.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Building wheel for peft (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "  Building wheel for accelerate (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m150.9/150.9 kB\u001b[0m \u001b[31m1.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m218.2/218.2 MB\u001b[0m \u001b[31m2.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.2/2.2 MB\u001b[0m \u001b[31m89.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m507.1/507.1 kB\u001b[0m \u001b[31m52.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m44.6/44.6 kB\u001b[0m \u001b[31m5.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m16.7/16.7 MB\u001b[0m \u001b[31m46.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m105.0/105.0 MB\u001b[0m \u001b[31m9.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m79.7/79.7 kB\u001b[0m \u001b[31m10.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m755.5/755.5 MB\u001b[0m \u001b[31m1.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m23.7/23.7 MB\u001b[0m \u001b[31m13.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m823.6/823.6 kB\u001b[0m \u001b[31m51.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m14.1/14.1 MB\u001b[0m \u001b[31m24.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m731.7/731.7 MB\u001b[0m \u001b[31m2.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m410.6/410.6 MB\u001b[0m \u001b[31m3.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m121.6/121.6 MB\u001b[0m \u001b[31m8.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.5/56.5 MB\u001b[0m \u001b[31m10.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m124.2/124.2 MB\u001b[0m \u001b[31m8.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m196.0/196.0 MB\u001b[0m \u001b[31m5.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m166.0/166.0 MB\u001b[0m \u001b[31m6.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m99.1/99.1 kB\u001b[0m \u001b[31m13.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m167.9/167.9 MB\u001b[0m \u001b[31m5.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m20.5/20.5 MB\u001b[0m \u001b[31m25.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m196.4/196.4 kB\u001b[0m \u001b[31m23.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m257.5/257.5 kB\u001b[0m \u001b[31m24.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m115.3/115.3 kB\u001b[0m \u001b[31m16.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m134.8/134.8 kB\u001b[0m \u001b[31m18.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m92.0/92.0 kB\u001b[0m \u001b[31m11.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m305.2/305.2 kB\u001b[0m \u001b[31m25.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m75.9/75.9 kB\u001b[0m \u001b[31m11.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m139.8/139.8 kB\u001b[0m \u001b[31m17.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m394.2/394.2 kB\u001b[0m \u001b[31m26.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m45.7/45.7 kB\u001b[0m \u001b[31m6.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.5/7.5 MB\u001b[0m \u001b[31m27.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m60.7/60.7 kB\u001b[0m \u001b[31m7.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m129.9/129.9 kB\u001b[0m \u001b[31m17.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m62.7/62.7 kB\u001b[0m \u001b[31m6.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.2/2.2 MB\u001b[0m \u001b[31m27.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m58.3/58.3 kB\u001b[0m \u001b[31m8.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m71.1/71.1 kB\u001b[0m \u001b[31m10.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m76.9/76.9 kB\u001b[0m \u001b[31m10.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m134.8/134.8 kB\u001b[0m \u001b[31m19.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Building wheel for ffmpy (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "lida 0.0.10 requires kaleido, which is not installed.\n",
            "llmx 0.0.15a0 requires cohere, which is not installed.\n",
            "llmx 0.0.15a0 requires openai, which is not installed.\n",
            "llmx 0.0.15a0 requires tiktoken, which is not installed.\n",
            "fastai 2.7.13 requires torch<2.2,>=1.10, but you have torch 2.2.0 which is incompatible.\n",
            "tensorflow-probability 0.22.0 requires typing-extensions<4.6.0, but you have typing-extensions 4.9.0 which is incompatible.\n",
            "torchaudio 2.1.0+cu121 requires torch==2.1.0, but you have torch 2.2.0 which is incompatible.\n",
            "torchdata 0.7.0 requires torch==2.1.0, but you have torch 2.2.0 which is incompatible.\n",
            "torchtext 0.16.0 requires torch==2.1.0, but you have torch 2.2.0 which is incompatible.\n",
            "torchvision 0.16.0+cu121 requires torch==2.1.0, but you have torch 2.2.0 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0m"
          ]
        }
      ],
      "source": [
        "!pip install -q -U git+https://github.com/huggingface/transformers.git\n",
        "!pip install -q -U git+https://github.com/huggingface/peft.git\n",
        "!pip install -q -U git+https://github.com/huggingface/accelerate.git\n",
        "!pip install -q trl xformers wandb datasets einops gradio sentencepiece bitsandbytes"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6M-SfndUzfv1"
      },
      "outputs": [],
      "source": [
        "from transformers import AutoModelForCausalLM, AutoTokenizer, BitsAndBytesConfig, HfArgumentParser, TrainingArguments, pipeline, logging, TextStreamer\n",
        "from peft import LoraConfig, PeftModel, prepare_model_for_kbit_training, get_peft_model\n",
        "import os,torch, wandb, platform, gradio, warnings\n",
        "from datasets import load_dataset\n",
        "from trl import SFTTrainer\n",
        "from huggingface_hub import notebook_login"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "G5ch55833Exn"
      },
      "outputs": [],
      "source": [
        "# Pre trained model\n",
        "model_name = \"meta-llama/Llama-2-7b-hf\"\n",
        "\n",
        "# Dataset name\n",
        "dataset_name = \"vicgalle/alpaca-gpt4\"\n",
        "\n",
        "# Hugging face repository link to save fine-tuned model(Create new repository in huggingface,copy and paste here)\n",
        "new_model = \"https://huggingface.co/kakashiCopyNinja/ft_Llama-2\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ufuPxlOQ4QE4"
      },
      "outputs": [],
      "source": [
        "notebook_login()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 122
        },
        "id": "cx0Gw_uk4y1H",
        "outputId": "93ce74f2-7d38-4a69-dfef-fa6711d8c450"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'Below is an instruction that describes a task. Write a response that appropriately completes the request.\\n\\n### Instruction:\\nGive three tips for staying healthy.\\n\\n### Response:\\n1. Eat a balanced and nutritious diet: Make sure your meals are inclusive of a variety of fruits and vegetables, lean protein, whole grains, and healthy fats. This helps to provide your body with the essential nutrients to function at its best and can help prevent chronic diseases.\\n\\n2. Engage in regular physical activity: Exercise is crucial for maintaining strong bones, muscles, and cardiovascular health. Aim for at least 150 minutes of moderate aerobic exercise or 75 minutes of vigorous exercise each week.\\n\\n3. Get enough sleep: Getting enough quality sleep is crucial for physical and mental well-being. It helps to regulate mood, improve cognitive function, and supports healthy growth and immune function. Aim for 7-9 hours of sleep each night.'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 10
        }
      ],
      "source": [
        "# Load dataset (you can process it here)\n",
        "dataset = load_dataset(dataset_name, split=\"train[0:10000]\")\n",
        "dataset[\"text\"][0]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 386,
          "referenced_widgets": [
            "a21c8d9d6a6f402e915055c3856e0eba",
            "8989e8d6bb414cdfaa10e53c3957e875",
            "0c36ba7a748d4514906292b427db855a",
            "f6df1ca30b794e9abc99ee975ada569f",
            "56ff9b1dca0c4db09fcd31c2c5d55a4f",
            "05904ecaff9646c1b4039197a72906dd",
            "aaf4b7e4c1164110a19858bcb79bd6ba",
            "b6613d29633c4782a9020d5ed72934b2",
            "0c2f6a7103b149fe84fe7e9666622424",
            "01a72a911def4390b8640937d7c1732c",
            "68e68c93fa504869938f9c4c501d15ea",
            "39d204e6e90f4d8a95d066bf4ba3c21a",
            "971931ef8bfb490d9ff75457b111b5be",
            "259d2dd323cb42f3b8a677736f3d52b0",
            "96780cb809b3456582bbb7b30350ecaf",
            "c7d7955f76e2495499132f9bd77f9b17",
            "d11621d238b24860bb8854366ee62ea7",
            "f193be3abe9644a88d935e41bcb2aae0",
            "6247828808d547e5b761c9c1edf3e3cb",
            "c365a2086913486789206e915a939e95",
            "afc21baef53440b58c00a5556eb0ed27",
            "01e44b16ea5649fe992b0f6a2c45cae4",
            "d00f4d0b7ae246ad877a135ed95b4091",
            "8587ed0f1f794179abf867a92313c526",
            "a1e9e7b70b6e4ae183ec500de61b5df0",
            "904c48a1aaa1472384326806b6e3d8d5",
            "a71b8448238d4a1f8913fc45139bec85",
            "41ecb137ee314b3b9f1eb32413db48a7",
            "eb56a75f456e4616af85bd8e4f4a7735",
            "64acd2a972694eefbf758ae7d3b5ec82",
            "eb21ae8834744074b1d574dabd886a42",
            "4297eab04d704ccb948c1ba1d1fc996d",
            "a3a0d801a5bc462ea25678a8df587dcd",
            "439ef3359df541b69b138aae4deeed6c",
            "cae8da1b64bf4dbd888b59773994b76e",
            "6053506e79cf4047869fb873473f1b76",
            "38245dd3a6084df498f5b187ff4759c9",
            "a0455bedb7ba49f29e1484406403071c",
            "7abe6781c3e7480fae04e5fd5e96d444",
            "1e9318bc69b7477c9d5bcb6764230422",
            "72e66d35db9744c1938e5d14a8b1364b",
            "987091ea621041bfab9e3f9f5dcb57c7",
            "50b9cae7c89d4b18a33233d51eca8999",
            "a7167816a2bc47898483afbbc2c54a5d",
            "ef37d2fe9685413a836e5bda0ec3688a",
            "4c76c9703ad940668cc0edc66e79cb50",
            "5b5d0a95512948d7b80082e191d4f9aa",
            "0d064019957a4c0ab3cdb865405fa807",
            "e5a0700e15654d7d9a7c9ecaa24a363b",
            "1f192063b3d045f292afa9e8ad9771b4",
            "679d501d7ead43b092eb68da10bcbe12",
            "accfc04a9994485d8b89fc14499a9832",
            "ad8f2ac70039427db2925eaf1d6b2027",
            "ce9c9f21616f4245862107db8df70c72",
            "8a24edf35e674116801e8cc652870a8d",
            "7b5c147c64fb4566acd4ae4e2eb09baa",
            "111070ca1545414abddbd5ccc948afa8",
            "04f7e0e2720f412a81a91f6e30428f98",
            "5294d5cadf7843498f969e4e22e94910",
            "004a35f44b0b4891a714d9c3fb5c6f25",
            "2371f83c45594db7adb900caa5ee9268",
            "1bd13a29902e4c199d0517be04a62424",
            "be9aeb632b2043dda11ce486878cb9b9",
            "e775df9202214077b69be2520fee3cd3",
            "fe1c136fba334bf182584bdc45da9218",
            "f2cd4388f17040e8b8010bed47a15bca",
            "ec9b850e7d124a74b2d7bb7ac6112a39",
            "f9262dc618614d5bbc8a7acb7deaf7fe",
            "63feed21846242eaafd9a64e7bd710bf",
            "39d17147b35943a6ab5bcc672b1f393d",
            "ca248ec9bbc04778a1e584b717cf6dbb",
            "a2d716c5e0ca40a09733ef80796ce7f5",
            "8f73ae471b0f48918686ab7f18c4ca59",
            "5e4e96a9f94d47d58db623881ef743d0",
            "3aec9cb8329e4bb1a668a3d8552e9936",
            "ae780fbc9c6048adb443fbc1401fe19c",
            "7e6a58be047f4173bbb11ef9914149ac",
            "1281073759ec4c90a0d30599431c51fc",
            "3f2cf70d43bb42b2be71d6ca7c7b1ca2",
            "241750ed7a664d14805b01169ee1c7b1",
            "f05e311d6afe458ca36bf4d15572018a",
            "423e975565f84503b365f9f090f11d9b",
            "1a0703491ad94c0392a6eb3de9b3faac",
            "710b26e14b1741eb9723668447f44fc3",
            "f7dddd897a224ba5a96f04459a4e032c",
            "b28574c8fe6049d298521ba7ad2184bc",
            "bd10521153ce456197d53fc4120f1ef1",
            "c8b0f0974d00453d88428ae297a1df8b",
            "c2402a094a03485a94f3e9b409370a74",
            "cf59d2575a2c4143b5a3fa7ec1f34795",
            "1d6a64d92d2f4bcaaac9ef4bac567d2f",
            "fc753866ca1e4cc8adf6d23b39d5ac3d",
            "fdd92bab39ef444ab7a67930d737bf07",
            "d3e09710f42541258369697893b25e67",
            "555dab6cb3be4788a635d174d7358e39",
            "c34c333a6912454bb936a987a8c5dca6",
            "20bc0b82851b40cebf442709c84210ce",
            "77db668c1fde480ea2e46036b007fc09",
            "f457567afb74453281bb5cd9819dd2e8",
            "50be29c532ab4926b002566ff92f9a25",
            "20468ce9ab3541c6beb8feb3280bc521",
            "d8f3baae44e54936806d5b53357e5e60",
            "49cfa015a798438a9e0d2574e86457de",
            "73698ad76ef64a21a630b7e10ac8c0ce",
            "dcb684e634824f01a0fd996e94377931",
            "99d0741e9e954a5ab78a013a83b76bb4",
            "deafd88bb21a4289ab7ec224651f96fb",
            "ef37a27126a04a5980feae1bfc7fb87f",
            "750c7757d4264165ad44e3a30a3addc8",
            "b3d85855c5be478b918efba0222ac021",
            "01b77c019d2e494683da863500958281",
            "b5b255454eac46298bfff7cd40a004d6",
            "68598d0bf25a41cbbf1c2b04a493b400",
            "19f7db7b06c147d2a0d82f02bfaa93fa",
            "9166d7a96b89465a86232f9d5d700d8f",
            "241971f7e79f4758ac700883f24a6310",
            "70eaf66088a44602b5d6e755a2ccad5a",
            "709ddb8a29b04da2b273500ffdeeb83e",
            "293eb94a3de04bc2a7d045e95e0573e0",
            "a162713b9d634c4eb67fad56a7011f4f",
            "0621e543f34540258b6cd3d6235e367d"
          ]
        },
        "id": "mNOa4WxP43n9",
        "outputId": "bb75c719-4a6f-4316-d120-11bf383983e1"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "config.json:   0%|          | 0.00/609 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "a21c8d9d6a6f402e915055c3856e0eba"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "model.safetensors.index.json:   0%|          | 0.00/26.8k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "39d204e6e90f4d8a95d066bf4ba3c21a"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Downloading shards:   0%|          | 0/2 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "d00f4d0b7ae246ad877a135ed95b4091"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "model-00001-of-00002.safetensors:   0%|          | 0.00/9.98G [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "439ef3359df541b69b138aae4deeed6c"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "model-00002-of-00002.safetensors:   0%|          | 0.00/3.50G [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "ef37d2fe9685413a836e5bda0ec3688a"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "7b5c147c64fb4566acd4ae4e2eb09baa"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "generation_config.json:   0%|          | 0.00/188 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "ec9b850e7d124a74b2d7bb7ac6112a39"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "tokenizer_config.json:   0%|          | 0.00/776 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "1281073759ec4c90a0d30599431c51fc"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "tokenizer.model:   0%|          | 0.00/500k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "c2402a094a03485a94f3e9b409370a74"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "tokenizer.json:   0%|          | 0.00/1.84M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "50be29c532ab4926b002566ff92f9a25"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "special_tokens_map.json:   0%|          | 0.00/414 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "01b77c019d2e494683da863500958281"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(True, True)"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ],
      "source": [
        "# Load base model(llama-2-7b-hf) and tokenizer\n",
        "bnb_config = BitsAndBytesConfig(\n",
        "    load_in_4bit= True,\n",
        "    bnb_4bit_quant_type= \"nf4\",\n",
        "    bnb_4bit_compute_dtype= torch.float16,\n",
        "    bnb_4bit_use_double_quant= False,\n",
        ")\n",
        "model = AutoModelForCausalLM.from_pretrained(\n",
        "    model_name,\n",
        "    quantization_config=bnb_config,\n",
        "    device_map={\"\": 0}\n",
        ")\n",
        "model = prepare_model_for_kbit_training(model)\n",
        "model.config.use_cache = False # silence the warnings. Please re-enable for inference!\n",
        "model.config.pretraining_tp = 1\n",
        "# Load LLaMA tokenizer\n",
        "tokenizer = AutoTokenizer.from_pretrained(model_name, trust_remote_code=True)\n",
        "tokenizer.pad_token = tokenizer.eos_token\n",
        "tokenizer.add_eos_token = True\n",
        "tokenizer.add_bos_token, tokenizer.add_eos_token"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 191
        },
        "id": "GapfZpIMBHTJ",
        "outputId": "ca2da9f4-570c-458d-fd19-e60858cbdc36"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: W&B API key is configured. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m If you're specifying your api key in code, ensure this code is not shared publicly.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Consider setting the WANDB_API_KEY environment variable, or running `wandb login` from the command line.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Appending key for api.wandb.ai to your netrc file: /root/.netrc\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mhellorohanp\u001b[0m (\u001b[33mft_llama-2\u001b[0m). Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Tracking run with wandb version 0.16.2"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Run data is saved locally in <code>/content/wandb/run-20240131_120926-hujq1jxx</code>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Syncing run <strong><a href='https://wandb.ai/ft_llama-2/Fine%20tuning%20llama-2-7B/runs/hujq1jxx' target=\"_blank\">ethereal-sky-2</a></strong> to <a href='https://wandb.ai/ft_llama-2/Fine%20tuning%20llama-2-7B' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View project at <a href='https://wandb.ai/ft_llama-2/Fine%20tuning%20llama-2-7B' target=\"_blank\">https://wandb.ai/ft_llama-2/Fine%20tuning%20llama-2-7B</a>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View run at <a href='https://wandb.ai/ft_llama-2/Fine%20tuning%20llama-2-7B/runs/hujq1jxx' target=\"_blank\">https://wandb.ai/ft_llama-2/Fine%20tuning%20llama-2-7B/runs/hujq1jxx</a>"
            ]
          },
          "metadata": {}
        }
      ],
      "source": [
        "#monitering login\n",
        "wandb.login(key=\"270cb7cb8c32aaf6eb78de4f275863a389a7d685\")\n",
        "run = wandb.init(project='Fine tuning llama-2-7B', job_type=\"training\", anonymous=\"allow\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WeH5VaNJGEwU"
      },
      "outputs": [],
      "source": [
        "peft_config = LoraConfig(\n",
        "    lora_alpha= 8,\n",
        "    lora_dropout= 0.1,\n",
        "    r= 16,\n",
        "    bias=\"none\",\n",
        "    task_type=\"CAUSAL_LM\",\n",
        "    target_modules=[\"q_proj\", \"k_proj\", \"v_proj\", \"o_proj\",\"gate_proj\", \"up_proj\"]\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NmsCVPG8GLJg"
      },
      "outputs": [],
      "source": [
        "training_arguments = TrainingArguments(\n",
        "    output_dir= \"./results\",\n",
        "    num_train_epochs= 1,\n",
        "    per_device_train_batch_size= 8,\n",
        "    gradient_accumulation_steps= 2,\n",
        "    optim = \"paged_adamw_8bit\",\n",
        "    save_steps= 1000,\n",
        "    logging_steps= 30,\n",
        "    learning_rate= 2e-4,\n",
        "    weight_decay= 0.001,\n",
        "    fp16= False,\n",
        "    bf16= False,\n",
        "    max_grad_norm= 0.3,\n",
        "    max_steps= -1,\n",
        "    warmup_ratio= 0.3,\n",
        "    group_by_length= True,\n",
        "    lr_scheduler_type= \"linear\",\n",
        "    report_to=\"wandb\",\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 104,
          "referenced_widgets": [
            "a41f00bf2d7945d780f958ba21c2c093",
            "89dec530e8eb4e2482f63b6d169f8c6d",
            "aba1fbdb20d049c984a3fc791302bef3",
            "b9f042dba9c5447580c4b6a5ee60aaee",
            "80e18a2fbd114910936a079910548550",
            "28091a07a5f04be6952e0f8e9861555c",
            "fd5885868c15406f8d6008afb88b31b9",
            "58243e3f8b4a409d963f5a07040fbd82",
            "dd7e4f4524a6417cb1ae78a24a2a2817",
            "21d76c86230e42a09837905c68af9d6f",
            "7029dd22842c4d8d948dcfd0d15ecd41"
          ]
        },
        "id": "jUogxsfIGOaM",
        "outputId": "183300cc-758d-4488-d82e-298021c811ad"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/trl/trainer/sft_trainer.py:223: UserWarning: You didn't pass a `max_seq_length` argument to the SFTTrainer, this will default to 1024\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Map:   0%|          | 0/10000 [00:00<?, ? examples/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "a41f00bf2d7945d780f958ba21c2c093"
            }
          },
          "metadata": {}
        }
      ],
      "source": [
        "# Setting sft parameters\n",
        "trainer = SFTTrainer(\n",
        "    model=model,\n",
        "    train_dataset=dataset,\n",
        "    peft_config=peft_config,\n",
        "    max_seq_length= None,\n",
        "    dataset_text_field=\"text\",\n",
        "    tokenizer=tokenizer,\n",
        "    args=training_arguments,\n",
        "    packing= False,\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 193
        },
        "id": "dXVTHOiwGiz9",
        "outputId": "6cce0aef-208b-4e75-a66a-712e38a495b9"
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "name 'trainer' is not defined",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-1-252f3821ece6>\u001b[0m in \u001b[0;36m<cell line: 2>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# Train model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mtrainer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m: name 'trainer' is not defined"
          ]
        }
      ],
      "source": [
        "# Train model\n",
        "trainer.train()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Load model directly\n",
        "from transformers import AutoTokenizer, AutoModelForCausalLM\n",
        "\n",
        "tokenizer = AutoTokenizer.from_pretrained(\"kakashiCopyNinja/ft_Llama-2\")\n",
        "model = AutoModelForCausalLM.from_pretrained(\"kakashiCopyNinja/ft_Llama-2\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 461,
          "referenced_widgets": [
            "ab9826d6d639427c8bc8dd7591b69144",
            "c0fe8d98da454cfd86dfaa2e78a28e39",
            "b04d48ae6bef442d88c586223129efe5",
            "7eec05a3bf3f41e1bf7a8e6f4e02b5ce",
            "0c61a5ec1b3a49ee97875f7dcdf915dd",
            "935f966276db43b09fc6bced6c18ecde",
            "37724edf463543f59d526f4a8fa7f879",
            "9b337c3fa6164127a4bdc40822b28337",
            "df93ae0eb53242c3b2a5e48cec54666d",
            "4239f98609d54843b0b0e01ceeeee5f3",
            "89e41b5c746e480ebea3281ffd676cad",
            "8113281599574deea36e4202da96972b",
            "35f24da946964ac38d86f2616facf253",
            "27a67d1cf761456bac85c9913fe906ee",
            "0568d00d409c483aa70fa631ec171092",
            "96f5902f95604f748f6f1acfe19176b5",
            "8871342827a547309859a7de4ab7e458",
            "7de59a864c6d472eb5d3f853e64b8ed8",
            "eab12392d2f548129938b6bfc72c0ab5",
            "9b7fa63ef70e40afb1f2175acf3bd47f",
            "e301fc334fdf4bdd9896bbc084ead4ba",
            "6c4bfa6bbc5846f8930e7aca517e2e98",
            "57ef4088161548e5aee0dae607a0d7e3",
            "6c1cf225ee9140568edba2667182a7c1",
            "f8063731c84243d0b2339d62b1a23b59",
            "364fe715b9e74e50ab41fd2c02da953f",
            "300bf4e27b374b2fa5e8f41ed5a67706",
            "5da29e370da5457d882cd87076d5fb99",
            "f4a633022c8745c48034abd92f44fcda",
            "79312d083a554a7290610f5d0e407c30",
            "851f46febbfb450a8e47d2665eca7674",
            "29f5cf6aabad403ab40c459057455eeb",
            "986f5cf6d8cc4eea9db0fb96ddb37d8f",
            "4b5dbbbc728a4caf9ea7ce352977702d",
            "744242d0505643308fed45ef407a01c2",
            "b5b940cf224a46e188a962a2f3baaa43",
            "f81f8732b3c4436cacebadfda5a13805",
            "f05504ab98dd4654bb414bdeb033719a",
            "4d6204ed2c48447e9d3e30743dcdd830",
            "8875d5e2653341bcaef58d6fc346c665",
            "4c25e13a5efc4042ac15a4f9dd3e74c9",
            "3afa4312c2b44978a32b2fd1dc0507fb",
            "3d2b91daa9dc44ff9a2fbc6e5d4117c9",
            "19f492c7b277495487d7928651b1b0ae",
            "3a23e3a3a881442a870850b7f0fac3bb",
            "79cf17fd28474e95b42bf246ea280a8b",
            "8ec056a3c251477790981c76712fad11",
            "c89aeb0581fe470b892d61b8938369a2",
            "e3dd12232c3d45cf94f419c43c825fd8",
            "4d9bab1bed3042a380075efe8b9af748",
            "08be542b30844d7db677fa258fa97eb0",
            "7e046b8f438d4b8cba5a627713fec98b",
            "2b4815566c5245c38e9b5a2d94402e0f",
            "40175bf511e24551b7aa8f260912cb6d",
            "2a84cccf01904b3783e1fe8cfab7b88b",
            "a5de1a93b97c45c29214239487dd1f0a",
            "745535d4cac646809c65b1f6562adbc9",
            "9fc32a08873f48c4a3bc94df34d41bc2",
            "b131e4341c374aa1aa9d29a10b095dfa",
            "dec252998db441e8b9e6b31bf857d2d2",
            "aa36a291c3f04c399486a44dd2b6997f",
            "36bf073745c14da4800072794a6af942",
            "330f81dc603f4da8a66049859edc6857",
            "d08c006aae2c445d8780f7aadf7e2278",
            "01da77a412f640d4b13da0e916c420f3",
            "8686ef529709436cbde8ca00f2ec3e6a",
            "d651f419dbbe4a7a8b1397b0062d20c4",
            "454f63727a174891b610f5ed7cdc5d73",
            "d68ff73fcee74f2bad8478237baf6e31",
            "b2ddf540ac844149a017e4e557630e46",
            "d58dbddcbf50493cadbf296c258473de",
            "e1de25380b8c493080b439d868043453",
            "adf232ab7c544257bc5455a1105180ac",
            "7def641896174bccb834f67ca360658e",
            "914236bb1e45481aa349f108643a5d35",
            "81ac79c6c2fa4045b4954530d16f7054",
            "86529d786ab645059614a066b3e397d9",
            "a14cb83154f74b79bbfce6225d8858fa",
            "a94283846c5b425c811b05fc42d63a40",
            "347d46fddecb4ae6b750eb486e19b9e8",
            "15d867f965164b5eb1fcccd5e9d677f0",
            "a093d18f7a6f4084a35c0cf594a603cf",
            "ef12325850d04df3bf61d62fa535ed35",
            "66662cb5d4644e2cb927e75dd619c63c",
            "486a559525e3436bb9918c4741078ec1",
            "920c72be4d714a59a78db1792bdeb91d",
            "e953b58a0f23490885e37979bd15cd02",
            "179ed9871ee9413485e603ca99779830",
            "6548064fce9441cba8f94ea73be74f62",
            "049017cdfe4c452ebbf4c8fde9c4c708",
            "1782bf41f2114bec85d4978436a4b208",
            "f8207b101d604c4ca9c58325b8a7d8e8",
            "5a8e9ed08f534434b7fae48aef53b470",
            "3d86845cf9e4484694e630743bea0d3c",
            "45072d010b674409b31d7f2cba947dcd",
            "a695262315994cf592d30d3fdbc7375c",
            "0ebf62d6104041a58a15bb34478c30e2",
            "dd1cbf9c4019437f8fd42bfb3a2a6a56",
            "6bf7721a16ba416a81f0683473cde2c3",
            "88e96c9351d24035966dcbfc9a1bc73d",
            "b9bc2fb84f93494bad502e749dd21c27",
            "9e3fed0567d04aa48d58894199e64b20",
            "8ba0cce402ca4890be09f1a0d380406a",
            "54a224c927e8455d949da3da790527a6",
            "92f3e2b160004769a415750fd66ca50f",
            "7f0a55055f3a45a3831b6ef435f50cd1",
            "694cbbf6f62840f5b9bd3068a3f03dd9",
            "da8b2fcccaee4e47bc928afe27e026d6",
            "fb4e46db652f4b419a4365f6218b4cba",
            "515e296f0eea49b89c9f7c8c4a70287f"
          ]
        },
        "id": "_CtiR4z-INhZ",
        "outputId": "0b4638e1-e98b-4f7c-bdc7-432fc5c81e3b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/huggingface_hub/utils/_token.py:88: UserWarning: \n",
            "The secret `HF_TOKEN` does not exist in your Colab secrets.\n",
            "To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n",
            "You will be able to reuse this secret in all of your notebooks.\n",
            "Please note that authentication is recommended but still optional to access public models or datasets.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "tokenizer_config.json:   0%|          | 0.00/920 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "ab9826d6d639427c8bc8dd7591b69144"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "tokenizer.model:   0%|          | 0.00/500k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "8113281599574deea36e4202da96972b"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "tokenizer.json:   0%|          | 0.00/1.84M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "57ef4088161548e5aee0dae607a0d7e3"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "special_tokens_map.json:   0%|          | 0.00/437 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "4b5dbbbc728a4caf9ea7ce352977702d"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "config.json:   0%|          | 0.00/689 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "3a23e3a3a881442a870850b7f0fac3bb"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "model.safetensors.index.json:   0%|          | 0.00/23.9k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "a5de1a93b97c45c29214239487dd1f0a"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Downloading shards:   0%|          | 0/3 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "d651f419dbbe4a7a8b1397b0062d20c4"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "model-00001-of-00003.safetensors:   0%|          | 0.00/4.94G [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "a14cb83154f74b79bbfce6225d8858fa"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "model-00002-of-00003.safetensors:   0%|          | 0.00/4.95G [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "6548064fce9441cba8f94ea73be74f62"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "model-00003-of-00003.safetensors:   0%|          | 0.00/3.59G [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "88e96c9351d24035966dcbfc9a1bc73d"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "stream"
      ],
      "metadata": {
        "id": "--HwN7pEJ-1c"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}